{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc566217-71e1-4f68-b587-ebb88b5c3ae5",
   "metadata": {},
   "source": [
    "pubmedbert model in huggingface:\n",
    "https://huggingface.co/NeuML/pubmedbert-base-embeddings\n",
    "\n",
    "The enviornment to run this code is called \"transformer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086a4c2e-0396-4942-b4e0-287bd5bafa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbc8731/miniconda3/envs/netmedgpt_llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ca63671-1183-42eb-baf9-db7c8b7fe34d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodes = pd.read_csv('data/nodes_snake.csv', sep= ',')\n",
    "node_names = nodes['node_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f21f288a-55c6-45a9-8132-60844e8e12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some NaN in the descriptions list, clean it: ensure all elements are strings\n",
    "node_names = [\"\" if pd.isna(i) else str(i) for i in node_names]\n",
    "\n",
    "# check if there is any Non-string left\n",
    "for idx, desc in enumerate(node_names):\n",
    "    if not isinstance(desc, str):\n",
    "        print(f\"Non-string at index {idx}: {desc} (type: {type(desc)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01d0cabb-7044-4619-ab3e-85ffc5a834c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def meanpooling(output, mask):\n",
    "    embeddings = output[0] # First element of model_output contains all token embeddings\n",
    "    mask = mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "    return torch.sum(embeddings * mask, 1) / torch.clamp(mask.sum(1), min=1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2b25c8a-edc4-4183-b9b6-fba3d1442ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"neuml/pubmedbert-base-embeddings\")\n",
    "model = AutoModel.from_pretrained(\"neuml/pubmedbert-base-embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a2ec294-403d-45c7-b22e-5ae43f48af36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[-0.0797, -0.4923, -0.3390,  ..., -0.7394,  0.0348, -0.1092],\n",
      "        [-0.5147, -0.7015, -0.2551,  ..., -0.5804,  0.5219, -0.2627],\n",
      "        [ 0.2139, -0.7698,  0.1177,  ..., -0.4510, -0.0762, -0.1129],\n",
      "        ...,\n",
      "        [-0.3003, -0.0267,  0.5011,  ...,  0.0611,  0.2385, -0.0895],\n",
      "        [-0.4699, -0.5239,  0.1228,  ..., -0.1884, -1.1497,  0.0826],\n",
      "        [-0.2361,  0.4123,  0.2347,  ..., -0.6276,  0.4826, -0.1514]])\n"
     ]
    }
   ],
   "source": [
    "attr = torch.empty((0, 768))\n",
    "# Tokenize sentences\n",
    "for i in node_names:\n",
    "    inputs = tokenizer(i, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "    \n",
    "    # Perform pooling. In this case, mean pooling.\n",
    "    emb = meanpooling(output, inputs['attention_mask'])\n",
    "    attr = torch.concat((attr, emb), dim = 0)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96f8dfca-d4d1-4a87-89d6-576c7220d556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([129375, 768])\n"
     ]
    }
   ],
   "source": [
    "print(attr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9bc911e-3385-4c76-9fdc-7fca2e87a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_df = pd.DataFrame(attr.numpy())\n",
    "attr_df.index = nodes['node_index']\n",
    "attr_df.to_csv(\"data/emb_pubmedbert_all_nodes.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1297ccc-0e82-4acc-bc44-0a596b967f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129375, 768)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891703e5-ca4b-41ea-91f0-c07071a7925f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
